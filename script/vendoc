#!/usr/bin/env python

# Copyright (c) 2013-2015 MIT Probabilistic Computing Project.
# 
# This file is part of Venture.
# 	
# Venture is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 	
# Venture is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 	
# You should have received a copy of the GNU General Public License
# along with Venture.  If not, see <http://www.gnu.org/licenses/>.

import sys
import string
import textwrap
import subprocess

from venture.lite.builtin import builtInSPsList
from venture.lite.inference_sps import inferenceSPsList
import venture.sivm.macro # To register the macros
from venture.sivm.macro_system import macros
import venture.engine.inference_prelude
from venture.shortcuts import Lite

def flags(psp):
  ans = []
  if psp.isRandom():
    ans += ["stochastic"]
  else:
    ans += ["deterministic"]
  # TODO Absorbing is very context-sensitive now; how do we handle this?
  # if psp.canAbsorb():
  #   ans += ["constrainable"]
  if psp.childrenCanAAA():
    ans += ["children can absorb at applications"]
  if psp.canEnumerate():
    ans += ["enumerable"]
  if psp.hasVariationalLKernel():
    ans += ["variationable"]
  # Simulation kernels and delta kernels are unused right now
  return ans

def indent(string, prefix):
  return "\n".join([prefix + line for line in string.strip().split("\n")])

def wrap_description(desc):
  desc_lines = desc.split("\n")
  if len(desc_lines) == 1:
    return desc_lines[0]
  else:
    return string.join(desc_lines[0:-1], "\n") + "\n" + textwrap.fill(desc_lines[-1],70)

def wrap_description_rst_format(header, body):
  return header + "\n\n" + indent(body, "   ")

def model_SPs():
  for (name,sp) in builtInSPsList:
    print ""
    print wrap_description(sp.description(name))
    print "  " + string.capitalize(string.join(flags(sp.outputPSP), ", "))

def model_SPs_rst_format():
  for (name,sp) in builtInSPsList:
    print ""
    print wrap_description_rst_format(*sp.description_rst_format(name))
    print
    print "   " + string.capitalize(string.join(flags(sp.outputPSP), ", "))

def inference_SPs_rst_format():
  for (name,sp) in inferenceSPsList:
    print ""
    print wrap_description_rst_format(*sp.description_rst_format(name))
    # The modeling-relevant tags do not help much with inference procedures
    # print
    # print "   " + string.capitalize(string.join(flags(sp.outputPSP), ", "))

def inference_prelude_SPs():
  for (_name, desc, _body) in venture.engine.inference_prelude.prelude:
    print ""
    print desc

def model_macros():
  for macro in macros:
    if macro.intended_for_inference(): continue
    if macro.desc is None:
      sys.stderr.write("Skipping undesribed macro %s\n" % (macro,))
      continue
    print macro.desc

def inference_macros():
  for macro in macros:
    if not macro.intended_for_inference(): continue
    if macro.desc is None:
      sys.stderr.write("Skipping undesribed macro %s\n" % (macro,))
      continue
    print macro.desc

def callbacks():
  ripl = Lite().make_church_prime_ripl()
  import inspect
  for (name, f) in ripl.sivm.core_sivm.engine.callbacks.iteritems():
    print ""
    print "- Callback ``%s``" % (name,)
    print indent(inspect.getdoc(f), "   ")

def invocation():
  for mode in ["", "lite ", "server ", "remote "]:
    print "\n::"
    cmd = "venture %s-h" % (mode,)
    print "\n   $ " + cmd
    sys.stdout.flush()
    subprocess.check_call(cmd + "| sed 's/^/   /'", shell=True)

if __name__ == "__main__":
  if len(sys.argv) > 1:
    if sys.argv[1] == "--rst":
      model_SPs_rst_format()
    elif sys.argv[1] == "inf":
      inference_SPs_rst_format()
      inference_prelude_SPs()
    elif sys.argv[1] == "macros":
      model_macros()
    elif sys.argv[1] == "inf-macros":
      inference_macros()
    elif sys.argv[1] == "callbacks":
      callbacks()
    elif sys.argv[1] == "invocation":
      invocation()
    else:
      raise Exception("Unknown object type %s" % (sys.argv[1],))
  else:
    model_SPs()
