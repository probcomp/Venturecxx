// A clustering model
define dpmm_model = {
  assume alpha     ~ gamma(1.0, 1.0) #concentration ;
  assume assign    = make_crp(1.0);
  assume z         = mem((row) ~> { assign() #cluster_assignment:row });
  assume V         = mem((col) ~> { gamma(1.0, 1.0) #relative_variance:col });
  assume component = mem((z, col) ~> { make_nig_normal(0.0, V(col), 1.0, 1.0) });
  assume datum     = mem((row, col) ~> { component(z(row), col)() });
};

// Define a synthetic data source that make a checkerboard pattern of
// large and small numbers with very low variance.  Clustering the
// rows should bring the even-numbered ones together, and the
// odd-numbered ones together.
define data_gen = (row, col) -> {
  if (int_mod(row + col, 2) == 0) {
    normal(-1000, 1)
  } else {
    normal(1000, 1)
  }
};

// Observe synthetic data on a complete rows x cols grid
define observations = (num_rows, num_cols) -> {
  for_each(arange(num_rows), (r) -> {
    for_each(arange(num_cols), (c) -> {
      observe datum(integer($r), integer($c)) = data_gen(r, c)
    })
  })
};

// The items we want to collect at every Markov chain iteration:
// - likelihood of the data
// - how many distinct clusters there are (should converge to 2)
define step_summary = (num_rows) -> {
  lls <- global_log_likelihood;
  assigns <- sample mapv(z, arange($num_rows));
  return(dict(
    ["logscore", lls[0]],
    ["num_clusters", size(unique(assigns))]))
};

// The inference program: sequential scan of Gibbs on discerete
// variables and repeated M-H on continuous ones.
define infer_gibbs_mh = (num_rows, num_cols, num_sweeps) -> {
  init <- step_summary(num_rows);
  rest <- mapM((sweep_ct) -> {
    repeat(10, resimulation_mh(minimal_subproblem(/?concentration)));
    for_each(arange(num_cols), (c) -> {
      repeat(10, resimulation_mh(minimal_subproblem(/?relative_variance==c))) });
    for_each(arange(num_rows), (r) -> {
      gibbs(minimal_subproblem(/?cluster_assignment==r)) });
    step_summary(num_rows)
  }, arange(num_sweeps));
  return(pair(init, rest))
};

// One replicate, as a suitable argument to mapv or parallel_mapv
define replicate = (num_sweeps, num_rows, num_cols) -> {
  (rep_id) -> {
    first(run(in_model(run(fork_model()), {
      likelihood_weight();
      hist <- infer_gibbs_resimulation_mh(num_rows, num_cols, num_sweeps);
      end <- sample dict(
        ["alpha", alpha],
        ["assignments", mapv(z, arange($num_rows))],
        ["V", mapv(V, arange($num_cols))]);
      return(list(hist, end))
  })))}
};

// Overall driver
define doit = (num_reps, num_cores, num_sweeps, num_rows, num_cols) -> {
  dpmm_model;
  observations(num_rows, num_cols);
  // Compute experimental results in parallel across replicates
  results <- parallel_mapv_action(replicate(num_sweeps, num_rows, num_cols),
    arange(num_reps), num_cores);
  // Or, in series
  // results = mapv(replicate(num_sweeps, num_rows, num_cols), arange(num_reps));
  data <- sample mapv((r) -> { mapv((c) -> { datum(r, c) }, arange($num_cols)) },
    arange($num_rows));
  action(make_plots(data, results))
};

// Run me with, e.g.,
// venture -f dpmm_example.vnts -L extensions.py -e 'doit(6, 3, 2, 8, 4)'
